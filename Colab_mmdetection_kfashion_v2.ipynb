{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 각 디렉토리(클래스)별로 train / val 으로 나누어 학습한 코드\n",
        "------------------------------------------------------------\n",
        "### kfashion 데이터셋의 디렉토리 별로 반복문을 사용해서 train/ val로 나누고 이 데이터셋을 학습시켰습니다. \n",
        "### 생성된 가중치 파일을 다시 불러와 train/val로 나눈 다음 디렉토리를 학습시켰습니다.\n",
        "### 위 두개의 과정을 계속 반복해, 각 클래스별로 학습시켰습니다.\n",
        "### kfashion 데이터셋을 로드하는 과정에서 데이터가 깨져서 발생한 에러때문에 학습이 되지 않습니다...😪"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W__gRTpDHjZH"
      },
      "source": [
        "## 환경 설정"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pIZLiYp3-Th3",
        "outputId": "6baee928-8e82-4ec7-9b26-cb650d94cd97"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "nvcc: NVIDIA (R) Cuda compiler driver\n",
            "Copyright (c) 2005-2021 NVIDIA Corporation\n",
            "Built on Sun_Feb_14_21:12:58_PST_2021\n",
            "Cuda compilation tools, release 11.2, V11.2.152\n",
            "Build cuda_11.2.r11.2/compiler.29618528_0\n",
            "gcc (Ubuntu 7.5.0-3ubuntu1~18.04) 7.5.0\n",
            "Copyright (C) 2017 Free Software Foundation, Inc.\n",
            "This is free software; see the source for copying conditions.  There is NO\n",
            "warranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Check nvcc version\n",
        "!nvcc -V\n",
        "# Check GCC version\n",
        "!gcc --version"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k2kkUYyv-aB2",
        "outputId": "710ef54f-ada3-4ecf-b206-101c2939c751"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Looking in links: https://download.pytorch.org/whl/torch_stable.html\n",
            "Requirement already satisfied: torch==1.9.0+cu111 in /usr/local/lib/python3.8/dist-packages (1.9.0+cu111)\n",
            "Requirement already satisfied: torchvision==0.10.0+cu111 in /usr/local/lib/python3.8/dist-packages (0.10.0+cu111)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.8/dist-packages (from torch==1.9.0+cu111) (4.4.0)\n",
            "Requirement already satisfied: pillow>=5.3.0 in /usr/local/lib/python3.8/dist-packages (from torchvision==0.10.0+cu111) (7.1.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from torchvision==0.10.0+cu111) (1.21.6)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Looking in links: https://download.openmmlab.com/mmcv/dist/cu111/torch1.9.0/index.html\n",
            "Collecting mmcv-full\n",
            "  Downloading https://download.openmmlab.com/mmcv/dist/cu111/torch1.9.0/mmcv_full-1.7.0-cp38-cp38-manylinux1_x86_64.whl (49.7 MB)\n",
            "\u001b[K     |████████████████████████████████| 49.7 MB 327 kB/s \n",
            "\u001b[?25hCollecting addict\n",
            "  Downloading addict-2.4.0-py3-none-any.whl (3.8 kB)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.8/dist-packages (from mmcv-full) (21.3)\n",
            "Requirement already satisfied: opencv-python>=3 in /usr/local/lib/python3.8/dist-packages (from mmcv-full) (4.6.0.66)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.8/dist-packages (from mmcv-full) (6.0)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.8/dist-packages (from mmcv-full) (7.1.2)\n",
            "Collecting yapf\n",
            "  Downloading yapf-0.32.0-py2.py3-none-any.whl (190 kB)\n",
            "\u001b[K     |████████████████████████████████| 190 kB 27.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from mmcv-full) (1.21.6)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging->mmcv-full) (3.0.9)\n",
            "Installing collected packages: yapf, addict, mmcv-full\n",
            "Successfully installed addict-2.4.0 mmcv-full-1.7.0 yapf-0.32.0\n",
            "Cloning into 'Kfashion'...\n",
            "remote: Enumerating objects: 203, done.\u001b[K\n",
            "remote: Counting objects: 100% (203/203), done.\u001b[K\n",
            "remote: Compressing objects: 100% (141/141), done.\u001b[K\n",
            "remote: Total 203 (delta 74), reused 142 (delta 53), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (203/203), 2.48 MiB | 27.94 MiB/s, done.\n",
            "Resolving deltas: 100% (74/74), done.\n",
            "/content/Kfashion/mmdetection/Kfashion\n",
            "Cloning into 'mmdetection'...\n",
            "remote: Enumerating objects: 32889, done.\u001b[K\n",
            "remote: Counting objects: 100% (204/204), done.\u001b[K\n",
            "remote: Compressing objects: 100% (190/190), done.\u001b[K\n",
            "remote: Total 32889 (delta 53), reused 93 (delta 13), pack-reused 32685\u001b[K\n",
            "Receiving objects: 100% (32889/32889), 44.98 MiB | 17.55 MiB/s, done.\n",
            "Resolving deltas: 100% (23166/23166), done.\n",
            "/content/Kfashion/mmdetection/Kfashion/mmdetection\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Obtaining file:///content/Kfashion/mmdetection/Kfashion/mmdetection\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.8/dist-packages (from mmdet==2.26.0) (3.2.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from mmdet==2.26.0) (1.21.6)\n",
            "Requirement already satisfied: pycocotools in /usr/local/lib/python3.8/dist-packages (from mmdet==2.26.0) (2.0.6)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.8/dist-packages (from mmdet==2.26.0) (1.7.3)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.8/dist-packages (from mmdet==2.26.0) (1.15.0)\n",
            "Requirement already satisfied: terminaltables in /usr/local/lib/python3.8/dist-packages (from mmdet==2.26.0) (3.1.10)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib->mmdet==2.26.0) (3.0.9)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib->mmdet==2.26.0) (2.8.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.8/dist-packages (from matplotlib->mmdet==2.26.0) (0.11.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib->mmdet==2.26.0) (1.4.4)\n",
            "Installing collected packages: mmdet\n",
            "  Attempting uninstall: mmdet\n",
            "    Found existing installation: mmdet 2.26.0\n",
            "    Can't uninstall 'mmdet'. No files were found to uninstall.\n",
            "  Running setup.py develop for mmdet\n",
            "Successfully installed mmdet-2.26.0\n"
          ]
        }
      ],
      "source": [
        "# install dependencies: (use cu111 because colab has CUDA 11.1)\n",
        "!pip install torch==1.9.0+cu111 torchvision==0.10.0+cu111 -f https://download.pytorch.org/whl/torch_stable.html\n",
        "\n",
        "# install mmcv-full thus we could use CUDA operators\n",
        "!pip install mmcv-full -f https://download.openmmlab.com/mmcv/dist/cu111/torch1.9.0/index.html\n",
        "\n",
        "# Install kfashion\n",
        "!rm -rf Kfashion\n",
        "!git clone https://github.com/sanso62/Kfashion.git\n",
        "%cd Kfashion\n",
        "\n",
        "# Install mmdetection\n",
        "!rm -rf mmdetection\n",
        "!git clone https://github.com/open-mmlab/mmdetection.git\n",
        "%cd mmdetection\n",
        "\n",
        "!pip install -e ."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2u1frXVZ-aZK",
        "outputId": "12580a91-5825-45c0-ac0c-feaba1606f89"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/mmcv/__init__.py:20: UserWarning: On January 1, 2023, MMCV will release v2.0.0, in which it will remove components related to the training process and add a data transformation module. In addition, it will rename the package names mmcv to mmcv-lite and mmcv-full to mmcv. See https://github.com/open-mmlab/mmcv/blob/master/docs/en/compatibility.md for more details.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "{'sys.platform': 'linux',\n",
              " 'Python': '3.8.16 (default, Dec  7 2022, 01:12:13) [GCC 7.5.0]',\n",
              " 'CUDA available': True,\n",
              " 'GPU 0': 'Tesla T4',\n",
              " 'CUDA_HOME': '/usr/local/cuda',\n",
              " 'NVCC': 'Cuda compilation tools, release 11.2, V11.2.152',\n",
              " 'GCC': 'x86_64-linux-gnu-gcc (Ubuntu 7.5.0-3ubuntu1~18.04) 7.5.0',\n",
              " 'PyTorch': '1.9.0+cu111',\n",
              " 'PyTorch compiling details': 'PyTorch built with:\\n  - GCC 7.3\\n  - C++ Version: 201402\\n  - Intel(R) Math Kernel Library Version 2020.0.0 Product Build 20191122 for Intel(R) 64 architecture applications\\n  - Intel(R) MKL-DNN v2.1.2 (Git Hash 98be7e8afa711dc9b66c8ff3504129cb82013cdb)\\n  - OpenMP 201511 (a.k.a. OpenMP 4.5)\\n  - NNPACK is enabled\\n  - CPU capability usage: AVX2\\n  - CUDA Runtime 11.1\\n  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86\\n  - CuDNN 8.0.5\\n  - Magma 2.5.2\\n  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.1, CUDNN_VERSION=8.0.5, CXX_COMPILER=/opt/rh/devtoolset-7/root/usr/bin/c++, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.9.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, \\n',\n",
              " 'TorchVision': '0.10.0+cu111',\n",
              " 'OpenCV': '4.6.0',\n",
              " 'MMCV': '1.7.0',\n",
              " 'MMCV Compiler': 'GCC 7.3',\n",
              " 'MMCV CUDA Compiler': '11.1'}"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from mmcv import collect_env\n",
        "collect_env()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RGk-thF5-iGn",
        "outputId": "f90e2729-4c99-4ee9-a31f-baaf3b0a1043"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1.9.0+cu111 True\n",
            "2.26.0\n",
            "11.1\n",
            "GCC 7.3\n"
          ]
        }
      ],
      "source": [
        "# Check Pytorch installation\n",
        "import torch, torchvision\n",
        "print(torch.__version__, torch.cuda.is_available())\n",
        "\n",
        "# Check MMDetection installation\n",
        "import mmdet\n",
        "print(mmdet.__version__)\n",
        "\n",
        "# Check mmcv installation\n",
        "from mmcv.ops import get_compiling_cuda_version, get_compiler_version\n",
        "print(get_compiling_cuda_version())\n",
        "print(get_compiler_version())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "573_0oqeIOSl"
      },
      "source": [
        "## Fine Tunning: Kfashion Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bnBGgCpR3xV6"
      },
      "source": [
        "Data Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DXbg8FTSrUBV",
        "outputId": "e8835959-e136-40e0-c7bd-255bf4fdab4a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "# load dataset\n",
        "# !wget https://github.com/matterport/Mask_RCNN/releases/download/v2.1/balloon_dataset.zip\n",
        "# !unzip -q balloon_dataset.zip\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "l7-pof6-4rIE"
      },
      "outputs": [],
      "source": [
        "import mmcv\n",
        "from mmcv.runner import load_checkpoint\n",
        "\n",
        "from mmdet.apis import inference_detector, show_result_pyplot, set_random_seed\n",
        "from mmdet.models import build_detector\n",
        "from mmdet.datasets import build_dataset\n",
        "from mmdet.models import build_detector\n",
        "from mmdet.apis import train_detector\n",
        "import datetime"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "29WLHCO6VIS9"
      },
      "outputs": [],
      "source": [
        "import copy\n",
        "import os.path as osp\n",
        "\n",
        "import mmcv\n",
        "import numpy as np\n",
        "\n",
        "from mmdet.datasets.builder import DATASETS\n",
        "from mmdet.datasets.custom import CustomDataset\n",
        "\n",
        "import json\n",
        "import zipfile\n",
        "import os\n",
        "import shutil\n",
        "import re\n",
        "import random\n",
        "import sys"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "qo4dezJrjWOg"
      },
      "outputs": [],
      "source": [
        "try:\n",
        "    shutil.rmtree(\"/content/Kfashion/mmdetection/datasetzip\")\n",
        "except:\n",
        "    pass"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "LLuVVZQZFqRH"
      },
      "outputs": [],
      "source": [
        "!rm -rf datasetzip\n",
        "!mkdir datasetzip\n",
        "!unzip -q /content/drive/MyDrive/Kfashion_dataset.zip -d /content/Kfashion/mmdetection/datasetzip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "0McOdJod1n80"
      },
      "outputs": [],
      "source": [
        "# coco dataset으로 프리 트레이닝된 mask_rcnn config 가져오기\n",
        "from mmcv import Config\n",
        "cfg = Config.fromfile('./configs/mask_rcnn/mask_rcnn_r50_caffe_fpn_mstrain-poly_1x_coco.py')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "385TwneFTkvx",
        "outputId": "2d3da089-59bb-4df5-eb5f-d1ea3e33c9a6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--2022-12-16 14:14:46--  https://download.openmmlab.com/mmdetection/v2.0/mask_rcnn/mask_rcnn_r50_caffe_fpn_mstrain-poly_3x_coco/mask_rcnn_r50_caffe_fpn_mstrain-poly_3x_coco_bbox_mAP-0.408__segm_mAP-0.37_20200504_163245-42aa3d00.pth\n",
            "Resolving download.openmmlab.com (download.openmmlab.com)... 163.181.82.219, 163.181.82.218, 163.181.82.215, ...\n",
            "Connecting to download.openmmlab.com (download.openmmlab.com)|163.181.82.219|:443... connected.\n",
            "HTTP request sent, awaiting response... 206 Partial Content\n",
            "Length: 177867103 (170M), 177867102 (170M) remaining [application/octet-stream]\n",
            "Saving to: ‘../log/latest.pth’\n",
            "\n",
            "../log/latest.pth   100%[===================>] 169.63M  12.8MB/s    in 16s     \n",
            "\n",
            "2022-12-16 14:15:06 (10.5 MB/s) - ‘../log/latest.pth’ saved [177867103/177867103]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget -c https://download.openmmlab.com/mmdetection/v2.0/mask_rcnn/mask_rcnn_r50_caffe_fpn_mstrain-poly_3x_coco/mask_rcnn_r50_caffe_fpn_mstrain-poly_3x_coco_bbox_mAP-0.408__segm_mAP-0.37_20200504_163245-42aa3d00.pth \\\n",
        "      -O ../log/latest.pth"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "Mn33CM91L_hg"
      },
      "outputs": [],
      "source": [
        "categories = [{\"id\": 0, \"name\": \"coat\"},\n",
        "              {\"id\": 1, \"name\": \"jacket\"},\n",
        "              {\"id\": 2, \"name\": \"jumper\"},\n",
        "              {\"id\": 3, \"name\": \"cardigan\"},\n",
        "              {\"id\": 4, \"name\": \"blouse\"},\n",
        "              {\"id\": 5, \"name\": \"t-shirt\"},\n",
        "              {\"id\": 6, \"name\": \"sweater\"},\n",
        "              {\"id\": 7, \"name\": \"shirt\"},\n",
        "              {\"id\": 8, \"name\": \"onepiece(dress)\"},\n",
        "              {\"id\": 9, \"name\": \"jumpsuite\"},\n",
        "              {\"id\": 10, \"name\": \"pants\"},\n",
        "              {\"id\": 11, \"name\": \"skirt\"}]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "3eOknXjsTkvt",
        "outputId": "6d990fab-e131-4f95-b8f1-042e646479aa"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "**\n",
            "<built-in function dir>\n",
            "**\n",
            "<built-in function dir>\n",
            "**\n",
            "<built-in function dir>\n",
            "**\n",
            "<built-in function dir>\n",
            "**\n",
            "<built-in function dir>\n",
            "**\n",
            "<built-in function dir>\n",
            "**\n",
            "<built-in function dir>\n",
            "**\n",
            "<built-in function dir>\n",
            "**\n",
            "<built-in function dir>\n",
            "**\n",
            "<built-in function dir>\n",
            "**\n",
            "<built-in function dir>\n",
            "**\n",
            "<built-in function dir>\n",
            "**\n",
            "<built-in function dir>\n",
            "**\n",
            "<built-in function dir>\n",
            "**\n",
            "<built-in function dir>\n",
            "data done\n",
            "Config:\n",
            "model = dict(\n",
            "    type='MaskRCNN',\n",
            "    backbone=dict(\n",
            "        type='ResNet',\n",
            "        depth=50,\n",
            "        num_stages=4,\n",
            "        out_indices=(0, 1, 2, 3),\n",
            "        frozen_stages=1,\n",
            "        norm_cfg=dict(type='BN', requires_grad=False),\n",
            "        norm_eval=True,\n",
            "        style='caffe',\n",
            "        init_cfg=dict(\n",
            "            type='Pretrained',\n",
            "            checkpoint='open-mmlab://detectron2/resnet50_caffe')),\n",
            "    neck=dict(\n",
            "        type='FPN',\n",
            "        in_channels=[256, 512, 1024, 2048],\n",
            "        out_channels=256,\n",
            "        num_outs=5),\n",
            "    rpn_head=dict(\n",
            "        type='RPNHead',\n",
            "        in_channels=256,\n",
            "        feat_channels=256,\n",
            "        anchor_generator=dict(\n",
            "            type='AnchorGenerator',\n",
            "            scales=[8],\n",
            "            ratios=[0.5, 1.0, 2.0],\n",
            "            strides=[4, 8, 16, 32, 64]),\n",
            "        bbox_coder=dict(\n",
            "            type='DeltaXYWHBBoxCoder',\n",
            "            target_means=[0.0, 0.0, 0.0, 0.0],\n",
            "            target_stds=[1.0, 1.0, 1.0, 1.0]),\n",
            "        loss_cls=dict(\n",
            "            type='CrossEntropyLoss', use_sigmoid=True, loss_weight=1.0),\n",
            "        loss_bbox=dict(type='L1Loss', loss_weight=1.0)),\n",
            "    roi_head=dict(\n",
            "        type='StandardRoIHead',\n",
            "        bbox_roi_extractor=dict(\n",
            "            type='SingleRoIExtractor',\n",
            "            roi_layer=dict(type='RoIAlign', output_size=7, sampling_ratio=0),\n",
            "            out_channels=256,\n",
            "            featmap_strides=[4, 8, 16, 32]),\n",
            "        bbox_head=dict(\n",
            "            type='Shared2FCBBoxHead',\n",
            "            in_channels=256,\n",
            "            fc_out_channels=1024,\n",
            "            roi_feat_size=7,\n",
            "            num_classes=12,\n",
            "            bbox_coder=dict(\n",
            "                type='DeltaXYWHBBoxCoder',\n",
            "                target_means=[0.0, 0.0, 0.0, 0.0],\n",
            "                target_stds=[0.1, 0.1, 0.2, 0.2]),\n",
            "            reg_class_agnostic=False,\n",
            "            loss_cls=dict(\n",
            "                type='CrossEntropyLoss', use_sigmoid=False, loss_weight=1.0),\n",
            "            loss_bbox=dict(type='L1Loss', loss_weight=1.0)),\n",
            "        mask_roi_extractor=dict(\n",
            "            type='SingleRoIExtractor',\n",
            "            roi_layer=dict(type='RoIAlign', output_size=14, sampling_ratio=0),\n",
            "            out_channels=256,\n",
            "            featmap_strides=[4, 8, 16, 32]),\n",
            "        mask_head=dict(\n",
            "            type='FCNMaskHead',\n",
            "            num_convs=4,\n",
            "            in_channels=256,\n",
            "            conv_out_channels=256,\n",
            "            num_classes=12,\n",
            "            loss_mask=dict(\n",
            "                type='CrossEntropyLoss', use_mask=True, loss_weight=1.0))),\n",
            "    train_cfg=dict(\n",
            "        rpn=dict(\n",
            "            assigner=dict(\n",
            "                type='MaxIoUAssigner',\n",
            "                pos_iou_thr=0.7,\n",
            "                neg_iou_thr=0.3,\n",
            "                min_pos_iou=0.3,\n",
            "                match_low_quality=True,\n",
            "                ignore_iof_thr=-1),\n",
            "            sampler=dict(\n",
            "                type='RandomSampler',\n",
            "                num=256,\n",
            "                pos_fraction=0.5,\n",
            "                neg_pos_ub=-1,\n",
            "                add_gt_as_proposals=False),\n",
            "            allowed_border=-1,\n",
            "            pos_weight=-1,\n",
            "            debug=False),\n",
            "        rpn_proposal=dict(\n",
            "            nms_pre=2000,\n",
            "            max_per_img=1000,\n",
            "            nms=dict(type='nms', iou_threshold=0.7),\n",
            "            min_bbox_size=0),\n",
            "        rcnn=dict(\n",
            "            assigner=dict(\n",
            "                type='MaxIoUAssigner',\n",
            "                pos_iou_thr=0.5,\n",
            "                neg_iou_thr=0.5,\n",
            "                min_pos_iou=0.5,\n",
            "                match_low_quality=True,\n",
            "                ignore_iof_thr=-1),\n",
            "            sampler=dict(\n",
            "                type='RandomSampler',\n",
            "                num=512,\n",
            "                pos_fraction=0.25,\n",
            "                neg_pos_ub=-1,\n",
            "                add_gt_as_proposals=True),\n",
            "            mask_size=28,\n",
            "            pos_weight=-1,\n",
            "            debug=False)),\n",
            "    test_cfg=dict(\n",
            "        rpn=dict(\n",
            "            nms_pre=1000,\n",
            "            max_per_img=1000,\n",
            "            nms=dict(type='nms', iou_threshold=0.7),\n",
            "            min_bbox_size=0),\n",
            "        rcnn=dict(\n",
            "            score_thr=0.05,\n",
            "            nms=dict(type='nms', iou_threshold=0.5),\n",
            "            max_per_img=100,\n",
            "            mask_thr_binary=0.5)))\n",
            "dataset_type = 'COCODataset'\n",
            "data_root = 'data/coco/'\n",
            "img_norm_cfg = dict(\n",
            "    mean=[103.53, 116.28, 123.675], std=[1.0, 1.0, 1.0], to_rgb=False)\n",
            "train_pipeline = [\n",
            "    dict(type='LoadImageFromFile'),\n",
            "    dict(\n",
            "        type='LoadAnnotations',\n",
            "        with_bbox=True,\n",
            "        with_mask=True,\n",
            "        poly2mask=False),\n",
            "    dict(\n",
            "        type='Resize',\n",
            "        img_scale=[(1333, 640), (1333, 672), (1333, 704), (1333, 736),\n",
            "                   (1333, 768), (1333, 800)],\n",
            "        multiscale_mode='value',\n",
            "        keep_ratio=True),\n",
            "    dict(type='RandomFlip', flip_ratio=0.5),\n",
            "    dict(\n",
            "        type='Normalize',\n",
            "        mean=[103.53, 116.28, 123.675],\n",
            "        std=[1.0, 1.0, 1.0],\n",
            "        to_rgb=False),\n",
            "    dict(type='Pad', size_divisor=32),\n",
            "    dict(type='DefaultFormatBundle'),\n",
            "    dict(type='Collect', keys=['img', 'gt_bboxes', 'gt_labels', 'gt_masks'])\n",
            "]\n",
            "test_pipeline = [\n",
            "    dict(type='LoadImageFromFile'),\n",
            "    dict(\n",
            "        type='MultiScaleFlipAug',\n",
            "        img_scale=(1333, 800),\n",
            "        flip=False,\n",
            "        transforms=[\n",
            "            dict(type='Resize', keep_ratio=True),\n",
            "            dict(type='RandomFlip'),\n",
            "            dict(\n",
            "                type='Normalize',\n",
            "                mean=[103.53, 116.28, 123.675],\n",
            "                std=[1.0, 1.0, 1.0],\n",
            "                to_rgb=False),\n",
            "            dict(type='Pad', size_divisor=32),\n",
            "            dict(type='ImageToTensor', keys=['img']),\n",
            "            dict(type='Collect', keys=['img'])\n",
            "        ])\n",
            "]\n",
            "data = dict(\n",
            "    samples_per_gpu=2,\n",
            "    workers_per_gpu=2,\n",
            "    train=dict(\n",
            "        type='CocoDataset',\n",
            "        ann_file=\n",
            "        '/content/Kfashion/mmdetection/kfashion/task_3-1_02top_04shirt_01-2022_08_23_05_52_15-coco 1.0.zip/train/annotation_kfashion.json',\n",
            "        img_prefix=\n",
            "        '/content/Kfashion/mmdetection/kfashion/task_3-1_02top_04shirt_01-2022_08_23_05_52_15-coco 1.0.zip/train/',\n",
            "        pipeline=[\n",
            "            dict(type='LoadImageFromFile'),\n",
            "            dict(\n",
            "                type='LoadAnnotations',\n",
            "                with_bbox=True,\n",
            "                with_mask=True,\n",
            "                poly2mask=False),\n",
            "            dict(\n",
            "                type='Resize',\n",
            "                img_scale=[(1333, 640), (1333, 672), (1333, 704), (1333, 736),\n",
            "                           (1333, 768), (1333, 800)],\n",
            "                multiscale_mode='value',\n",
            "                keep_ratio=True),\n",
            "            dict(type='RandomFlip', flip_ratio=0.5),\n",
            "            dict(\n",
            "                type='Normalize',\n",
            "                mean=[103.53, 116.28, 123.675],\n",
            "                std=[1.0, 1.0, 1.0],\n",
            "                to_rgb=False),\n",
            "            dict(type='Pad', size_divisor=32),\n",
            "            dict(type='DefaultFormatBundle'),\n",
            "            dict(\n",
            "                type='Collect',\n",
            "                keys=['img', 'gt_bboxes', 'gt_labels', 'gt_masks'])\n",
            "        ],\n",
            "        classes=('coat', 'jacket', 'jumper', 'cardigan', 'blouse', 't-shirt',\n",
            "                 'sweater', 'shirt', 'onepiece(dress)', 'jumpsuite', 'pants',\n",
            "                 'skirt')),\n",
            "    val=dict(\n",
            "        type='CocoDataset',\n",
            "        ann_file=\n",
            "        '/content/Kfashion/mmdetection/kfashion/task_3-1_02top_04shirt_01-2022_08_23_05_52_15-coco 1.0.zip/val/annotation_kfashion.json',\n",
            "        img_prefix=\n",
            "        '/content/Kfashion/mmdetection/kfashion/task_3-1_02top_04shirt_01-2022_08_23_05_52_15-coco 1.0.zip/val/',\n",
            "        pipeline=[\n",
            "            dict(type='LoadImageFromFile'),\n",
            "            dict(\n",
            "                type='MultiScaleFlipAug',\n",
            "                img_scale=(1333, 800),\n",
            "                flip=False,\n",
            "                transforms=[\n",
            "                    dict(type='Resize', keep_ratio=True),\n",
            "                    dict(type='RandomFlip'),\n",
            "                    dict(\n",
            "                        type='Normalize',\n",
            "                        mean=[103.53, 116.28, 123.675],\n",
            "                        std=[1.0, 1.0, 1.0],\n",
            "                        to_rgb=False),\n",
            "                    dict(type='Pad', size_divisor=32),\n",
            "                    dict(type='ImageToTensor', keys=['img']),\n",
            "                    dict(type='Collect', keys=['img'])\n",
            "                ])\n",
            "        ],\n",
            "        classes=('coat', 'jacket', 'jumper', 'cardigan', 'blouse', 't-shirt',\n",
            "                 'sweater', 'shirt', 'onepiece(dress)', 'jumpsuite', 'pants',\n",
            "                 'skirt')),\n",
            "    test=dict(\n",
            "        type='CocoDataset',\n",
            "        ann_file=\n",
            "        '/content/Kfashion/mmdetection/kfashion/task_3-1_02top_04shirt_01-2022_08_23_05_52_15-coco 1.0.zip/val/annotation_kfashion.json',\n",
            "        img_prefix=\n",
            "        '/content/Kfashion/mmdetection/kfashion/task_3-1_02top_04shirt_01-2022_08_23_05_52_15-coco 1.0.zip/val/',\n",
            "        pipeline=[\n",
            "            dict(type='LoadImageFromFile'),\n",
            "            dict(\n",
            "                type='MultiScaleFlipAug',\n",
            "                img_scale=(1333, 800),\n",
            "                flip=False,\n",
            "                transforms=[\n",
            "                    dict(type='Resize', keep_ratio=True),\n",
            "                    dict(type='RandomFlip'),\n",
            "                    dict(\n",
            "                        type='Normalize',\n",
            "                        mean=[103.53, 116.28, 123.675],\n",
            "                        std=[1.0, 1.0, 1.0],\n",
            "                        to_rgb=False),\n",
            "                    dict(type='Pad', size_divisor=32),\n",
            "                    dict(type='ImageToTensor', keys=['img']),\n",
            "                    dict(type='Collect', keys=['img'])\n",
            "                ])\n",
            "        ],\n",
            "        classes=('coat', 'jacket', 'jumper', 'cardigan', 'blouse', 't-shirt',\n",
            "                 'sweater', 'shirt', 'onepiece(dress)', 'jumpsuite', 'pants',\n",
            "                 'skirt')))\n",
            "evaluation = dict(metric=['bbox', 'segm'], interval=12)\n",
            "optimizer = dict(type='SGD', lr=0.0025, momentum=0.9, weight_decay=0.0001)\n",
            "optimizer_config = dict(grad_clip=None)\n",
            "lr_config = dict(\n",
            "    policy='step',\n",
            "    warmup=None,\n",
            "    warmup_iters=500,\n",
            "    warmup_ratio=0.001,\n",
            "    step=[8, 11])\n",
            "runner = dict(type='EpochBasedRunner', max_epochs=12)\n",
            "checkpoint_config = dict(interval=12)\n",
            "log_config = dict(\n",
            "    interval=10,\n",
            "    hooks=[dict(type='TextLoggerHook'),\n",
            "           dict(type='TensorboardLoggerHook')])\n",
            "custom_hooks = [dict(type='NumClassCheckHook')]\n",
            "dist_params = dict(backend='nccl')\n",
            "log_level = 'INFO'\n",
            "load_from = '../log/latest.pth'\n",
            "resume_from = None\n",
            "workflow = [('train', 1)]\n",
            "opencv_num_threads = 0\n",
            "mp_start_method = 'fork'\n",
            "auto_scale_lr = dict(enable=False, base_batch_size=16)\n",
            "work_dir = '../log/'\n",
            "seed = 0\n",
            "device = 'cuda'\n",
            "gpu_ids = range(0, 1)\n",
            "\n",
            "Config done\n",
            "loading annotations into memory...\n",
            "Done (t=0.01s)\n",
            "creating index...\n",
            "index created!\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2022-12-16 14:15:50,241 - mmdet - INFO - Automatic scaling of learning rate (LR) has been disabled.\n",
            "2022-12-16 14:15:50,252 - mmdet - INFO - load checkpoint from local path: ../log/latest.pth\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loading annotations into memory...\n",
            "Done (t=0.00s)\n",
            "creating index...\n",
            "index created!\n"
          ]
        },
        {
          "ename": "UnpicklingError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mUnpicklingError\u001b[0m                           Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-16-73f906b1506a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    130\u001b[0m     \u001b[0mmmcv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmkdir_or_exist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mosp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabspath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcfg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwork_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    131\u001b[0m     \u001b[0;31m# add timestamp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 132\u001b[0;31m     \u001b[0mtrain_detector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdatasets\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcfg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdistributed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimestamp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdatetime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatetime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrftime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"%Y%m%d-%H%M%S\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/content/Kfashion/mmdetection/Kfashion/mmdetection/mmdet/apis/train.py\u001b[0m in \u001b[0;36mtrain_detector\u001b[0;34m(model, dataset, cfg, distributed, validate, timestamp, meta)\u001b[0m\n\u001b[1;32m    243\u001b[0m         \u001b[0mrunner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresume\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcfg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresume_from\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    244\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mcfg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_from\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 245\u001b[0;31m         \u001b[0mrunner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_checkpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcfg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_from\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    246\u001b[0m     \u001b[0mrunner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_loaders\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcfg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mworkflow\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/mmcv/runner/base_runner.py\u001b[0m in \u001b[0;36mload_checkpoint\u001b[0;34m(self, filename, map_location, strict, revise_keys)\u001b[0m\n\u001b[1;32m    347\u001b[0m         \u001b[0mrevise_keys\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mList\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mr'^module.'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    348\u001b[0m     ) -> Union[Dict, OrderedDict]:\n\u001b[0;32m--> 349\u001b[0;31m         return load_checkpoint(\n\u001b[0m\u001b[1;32m    350\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    351\u001b[0m             \u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/mmcv/runner/checkpoint.py\u001b[0m in \u001b[0;36mload_checkpoint\u001b[0;34m(model, filename, map_location, strict, logger, revise_keys)\u001b[0m\n\u001b[1;32m    636\u001b[0m         \u001b[0mdict\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mOrderedDict\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mThe\u001b[0m \u001b[0mloaded\u001b[0m \u001b[0mcheckpoint\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    637\u001b[0m     \"\"\"\n\u001b[0;32m--> 638\u001b[0;31m     \u001b[0mcheckpoint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_load_checkpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_location\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogger\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    639\u001b[0m     \u001b[0;31m# OrderedDict is a subclass of dict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    640\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcheckpoint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/mmcv/runner/checkpoint.py\u001b[0m in \u001b[0;36m_load_checkpoint\u001b[0;34m(filename, map_location, logger)\u001b[0m\n\u001b[1;32m    570\u001b[0m            \u001b[0minformation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwhich\u001b[0m \u001b[0mdepends\u001b[0m \u001b[0mon\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mcheckpoint\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    571\u001b[0m     \"\"\"\n\u001b[0;32m--> 572\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mCheckpointLoader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_checkpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_location\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogger\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    573\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    574\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/mmcv/runner/checkpoint.py\u001b[0m in \u001b[0;36mload_checkpoint\u001b[0;34m(cls, filename, map_location, logger)\u001b[0m\n\u001b[1;32m    312\u001b[0m         mmcv.print_log(\n\u001b[1;32m    313\u001b[0m             f'load checkpoint from {class_name[10:]} path: {filename}', logger)\n\u001b[0;32m--> 314\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mcheckpoint_loader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_location\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    315\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    316\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/mmcv/runner/checkpoint.py\u001b[0m in \u001b[0;36mload_from_local\u001b[0;34m(filename, map_location)\u001b[0m\n\u001b[1;32m    332\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mosp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misfile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    333\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mFileNotFoundError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'{filename} can not be found.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 334\u001b[0;31m     \u001b[0mcheckpoint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_location\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmap_location\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    335\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mcheckpoint\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    336\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, **pickle_load_args)\u001b[0m\n\u001b[1;32m    606\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopened_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    607\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0m_load\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopened_zipfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_location\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpickle_load_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 608\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_legacy_load\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopened_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_location\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpickle_load_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    609\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    610\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36m_legacy_load\u001b[0;34m(f, map_location, pickle_module, **pickle_load_args)\u001b[0m\n\u001b[1;32m    775\u001b[0m             \"functionality.\")\n\u001b[1;32m    776\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 777\u001b[0;31m     \u001b[0mmagic_number\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpickle_load_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    778\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mmagic_number\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mMAGIC_NUMBER\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    779\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Invalid magic number; corrupt file?\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mUnpicklingError\u001b[0m: invalid load key, '\\x0a'."
          ]
        }
      ],
      "source": [
        "for (_, _, files) in os.walk(\"/content/Kfashion/mmdetection/datasetzip\"):\n",
        "    for i,f in enumerate(files):\n",
        "        try:\n",
        "            print(\"**\")\n",
        "            shutil.rmtree(\"/content/Kfashion/mmdetection/kfashion\")\n",
        "        except:\n",
        "            pass\n",
        "        os.mkdir(\"/content/Kfashion/mmdetection/kfashion/\")\n",
        "        zipfile.ZipFile(\"/content/Kfashion/mmdetection/datasetzip/\"+f).extractall(\"/content/Kfashion/mmdetection/kfashion/\"+f)\n",
        "        # shutil.unpack_archive(\"/content/Kfashion/mmdetection/datasetzip/\"+f, \"/content/Kfashion/mmdetection/kfashion/\"+f, \"zip\")\n",
        "        os.mkdir(\"/content/Kfashion/mmdetection/kfashion/\"+f+\"/train\")\n",
        "        os.mkdir(\"/content/Kfashion/mmdetection/kfashion/\"+f+\"/val\")\n",
        "        print(dir)\n",
        "        train_img_id_list={}\n",
        "        val_img_id_list={}\n",
        "        train_images=[]\n",
        "        val_images=[]\n",
        "        train_annotations=[]\n",
        "        val_annotations=[]\n",
        "        with open(\"/content/Kfashion/mmdetection/kfashion/\"+f+\"/annotations/instances_default.json\", \"r\") as file:\n",
        "            label=json.load(file)\n",
        "            random.shuffle(label[\"images\"])\n",
        "            len_images=len(label[\"images\"])\n",
        "            for img in label[\"images\"][:int(len_images*0.9)]:\n",
        "                file_name=re.sub(\"/.*/\",\"\",img[\"file_name\"])\n",
        "                train_img_id_list[file_name]=img[\"id\"]\n",
        "                img[\"file_name\"]=file_name\n",
        "                train_images.append(img)   \n",
        "\n",
        "            for img in label[\"images\"][int(len_images*0.9):]:\n",
        "                file_name=re.sub(\"/.*/\",\"\",img[\"file_name\"])\n",
        "                val_img_id_list[file_name]=img[\"id\"]\n",
        "                img[\"file_name\"]=file_name\n",
        "                val_images.append(img)  \n",
        "\n",
        "            category=label[\"categories\"][0][\"name\"]\n",
        "            for c in categories:\n",
        "              if c[\"name\"]==category:\n",
        "                category_id=c[\"id\"]\n",
        "                break\n",
        "\n",
        "            for ann in label[\"annotations\"]:\n",
        "                ann[\"category_id\"]=category_id\n",
        "                if ann[\"image_id\"] in train_img_id_list.values():\n",
        "                    train_annotations.append(ann)\n",
        "                elif ann[\"image_id\"] in val_img_id_list.values():\n",
        "                    val_annotations.append(ann)\n",
        "\n",
        "                \n",
        "\n",
        "\n",
        "        jsondata=dict([(\"categories\", categories), (\"images\", train_images), (\"annotations\", train_annotations) ])\n",
        "        with open(\"/content/Kfashion/mmdetection/kfashion/\"+f+\"/train/annotation_kfashion.json\", \"w\") as tf:\n",
        "            json.dump(jsondata, tf)\n",
        "        \n",
        "        jsondata=dict([(\"categories\", categories), (\"images\", val_images), (\"annotations\", val_annotations) ])\n",
        "        with open(f\"/content/Kfashion/mmdetection/kfashion/{f}/val/annotation_kfashion.json\", \"w\") as vf:\n",
        "            json.dump(jsondata, vf)\n",
        "\n",
        "        for img_name in train_img_id_list.keys():        \n",
        "            shutil.move(\"/content/Kfashion/mmdetection/kfashion/\"+f+\"/images/\"+img_name, \"/content/Kfashion/mmdetection/kfashion/\"+f+\"/train/\"+img_name)\n",
        "        for img_name in val_img_id_list.keys():        \n",
        "            shutil.move(\"/content/Kfashion/mmdetection/kfashion/\"+f+\"/images/\"+img_name, \"/content/Kfashion/mmdetection/kfashion/\"+f+\"/val/\"+img_name)\n",
        "    \n",
        "    print(\"data done\")\n",
        "    # Modify dataset type and path\n",
        "\n",
        "    cfg.dataset_type = 'COCODataset'\n",
        "\n",
        "\n",
        "    cfg.data.test.ann_file = \"/content/Kfashion/mmdetection/kfashion/\"+f+\"/val/annotation_kfashion.json\"\n",
        "    cfg.data.test.img_prefix = \"/content/Kfashion/mmdetection/kfashion/\"+f+\"/val/\"\n",
        "    cfg.data.test.classes = (\"coat\", \"jacket\", \"jumper\", \"cardigan\", \"blouse\", \"t-shirt\",\"sweater\", \"shirt\", \"onepiece(dress)\", \"jumpsuite\", \"pants\", \"skirt\")\n",
        "\n",
        "\n",
        "    cfg.data.train.ann_file = \"/content/Kfashion/mmdetection/kfashion/\"+f+\"/train/annotation_kfashion.json\"\n",
        "    cfg.data.train.img_prefix = \"/content/Kfashion/mmdetection/kfashion/\"+f+\"/train/\"\n",
        "    cfg.data.train.classes = (\"coat\", \"jacket\", \"jumper\", \"cardigan\", \"blouse\", \"t-shirt\",\"sweater\", \"shirt\", \"onepiece(dress)\", \"jumpsuite\", \"pants\", \"skirt\")\n",
        "\n",
        "\n",
        "    cfg.data.val.ann_file = \"/content/Kfashion/mmdetection/kfashion/\"+f+\"/val/annotation_kfashion.json\"\n",
        "    cfg.data.val.img_prefix = \"/content/Kfashion/mmdetection/kfashion/\"+f+\"/val/\"\n",
        "    cfg.data.val.classes = (\"coat\", \"jacket\", \"jumper\", \"cardigan\", \"blouse\", \"t-shirt\",\"sweater\", \"shirt\", \"onepiece(dress)\", \"jumpsuite\", \"pants\", \"skirt\")\n",
        "\n",
        "\n",
        "    # # modify num classes of the model in box head\n",
        "    # cfg.model.roi_head.bbox_head.num_classes = 80\n",
        "    # # modify num classes of the model in box head and mask head\n",
        "    cfg.model.roi_head.bbox_head.num_classes = 12\n",
        "    cfg.model.roi_head.mask_head.num_classes = 12\n",
        "    # If we need to finetune a model based on a pre-trained detector, we need to\n",
        "    # use load_from to set the path of log.\n",
        "    cfg.load_from = '../log/latest.pth'\n",
        "\n",
        "    # Set up working dir to save files and logs.\n",
        "    cfg.work_dir = '../log/'\n",
        "\n",
        "    # The original learning rate (LR) is set for 8-GPU training.\n",
        "    # We divide it by 8 since we only use one GPU.\n",
        "    cfg.optimizer.lr = 0.02 / 8\n",
        "    cfg.lr_config.warmup = None\n",
        "    cfg.log_config.interval = 10\n",
        "\n",
        "    # Change the evaluation metric since we use customized dataset.\n",
        "    # cfg.evaluation.metric = 'mAP'/\n",
        "    # We can set the evaluation interval to reduce the evaluation times\n",
        "    cfg.evaluation.interval = 12\n",
        "    # We can set the checkpoint saving interval to reduce the storage cost\n",
        "    cfg.checkpoint_config.interval = 12\n",
        "\n",
        "    cfg.seed = 0\n",
        "    set_random_seed(0, deterministic=False)\n",
        "    cfg.device = 'cuda'\n",
        "    cfg.gpu_ids = range(1)\n",
        "\n",
        "    cfg.log_config.hooks = [\n",
        "        dict(type='TextLoggerHook'),\n",
        "        dict(type='TensorboardLoggerHook')]\n",
        "    print(f'Config:\\n{cfg.pretty_text}')\n",
        "\n",
        "    print(\"Config done\")\n",
        "\n",
        "\n",
        "    datasets = [build_dataset(cfg.data.train)]\n",
        "    model = build_detector(cfg.model)\n",
        "    model.CLASSES = datasets[0].CLASSES\n",
        "    mmcv.mkdir_or_exist(osp.abspath(cfg.work_dir))\n",
        "    # add timestamp\n",
        "    train_detector(model, datasets, cfg, distributed=False, validate=True, timestamp=datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FCxmD0OGTkvz"
      },
      "source": [
        "## 로그 시각화"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "32Lm-EfSTkvz"
      },
      "outputs": [],
      "source": [
        "\n",
        "%load_ext tensorboard\n",
        "%tensorboard --logdir ./tutorial_exps"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WomGhWs36AYF"
      },
      "source": [
        "# Detection 결과"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Bt94A9v4GvzY"
      },
      "outputs": [],
      "source": [
        "img = mmcv.imread('./balloon/sample.jpg') # 테스트할 샘플이미지의 경로명 입력\n",
        "\n",
        "model.cfg = cfg\n",
        "result = inference_detector(model, img)\n",
        "show_result_pyplot(model, img, result)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.9 (tags/v3.10.9:1dd9be6, Dec  6 2022, 20:01:21) [MSC v.1934 64 bit (AMD64)]"
    },
    "vscode": {
      "interpreter": {
        "hash": "d4f0abf4b4e06a550281b258cd6c810d114c729ed8b8996b13462e88057d1b62"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
