{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ê° ë””ë ‰í† ë¦¬(í´ëž˜ìŠ¤)ë³„ë¡œ train / val ìœ¼ë¡œ ë‚˜ëˆ„ì–´ í•™ìŠµí•œ ì½”ë“œ\n",
        "------------------------------------------------------------\n",
        "### kfashion ë°ì´í„°ì…‹ì˜ ë””ë ‰í† ë¦¬ ë³„ë¡œ ë°˜ë³µë¬¸ì„ ì‚¬ìš©í•´ì„œ train/ valë¡œ ë‚˜ëˆ„ê³  ì´ ë°ì´í„°ì…‹ì„ í•™ìŠµì‹œì¼°ìŠµë‹ˆë‹¤. \n",
        "### ìƒì„±ëœ ê°€ì¤‘ì¹˜ íŒŒì¼ì„ ë‹¤ì‹œ ë¶ˆëŸ¬ì™€ train/valë¡œ ë‚˜ëˆˆ ë‹¤ìŒ ë””ë ‰í† ë¦¬ë¥¼ í•™ìŠµì‹œì¼°ìŠµë‹ˆë‹¤.\n",
        "### ìœ„ ë‘ê°œì˜ ê³¼ì •ì„ ê³„ì† ë°˜ë³µí•´, ê° í´ëž˜ìŠ¤ë³„ë¡œ í•™ìŠµì‹œì¼°ìŠµë‹ˆë‹¤.\n",
        "### kfashion ë°ì´í„°ì…‹ì„ ë¡œë“œí•˜ëŠ” ê³¼ì •ì—ì„œ ë°ì´í„°ê°€ ê¹¨ì ¸ì„œ ë°œìƒí•œ ì—ëŸ¬ë•Œë¬¸ì— í•™ìŠµì´ ë˜ì§€ ì•ŠìŠµë‹ˆë‹¤...ðŸ˜ª"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W__gRTpDHjZH"
      },
      "source": [
        "## í™˜ê²½ ì„¤ì •"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pIZLiYp3-Th3",
        "outputId": "6baee928-8e82-4ec7-9b26-cb650d94cd97"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "nvcc: NVIDIA (R) Cuda compiler driver\n",
            "Copyright (c) 2005-2021 NVIDIA Corporation\n",
            "Built on Sun_Feb_14_21:12:58_PST_2021\n",
            "Cuda compilation tools, release 11.2, V11.2.152\n",
            "Build cuda_11.2.r11.2/compiler.29618528_0\n",
            "gcc (Ubuntu 7.5.0-3ubuntu1~18.04) 7.5.0\n",
            "Copyright (C) 2017 Free Software Foundation, Inc.\n",
            "This is free software; see the source for copying conditions.  There is NO\n",
            "warranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Check nvcc version\n",
        "!nvcc -V\n",
        "# Check GCC version\n",
        "!gcc --version"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k2kkUYyv-aB2",
        "outputId": "710ef54f-ada3-4ecf-b206-101c2939c751"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Looking in links: https://download.pytorch.org/whl/torch_stable.html\n",
            "Requirement already satisfied: torch==1.9.0+cu111 in /usr/local/lib/python3.8/dist-packages (1.9.0+cu111)\n",
            "Requirement already satisfied: torchvision==0.10.0+cu111 in /usr/local/lib/python3.8/dist-packages (0.10.0+cu111)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.8/dist-packages (from torch==1.9.0+cu111) (4.4.0)\n",
            "Requirement already satisfied: pillow>=5.3.0 in /usr/local/lib/python3.8/dist-packages (from torchvision==0.10.0+cu111) (7.1.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from torchvision==0.10.0+cu111) (1.21.6)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Looking in links: https://download.openmmlab.com/mmcv/dist/cu111/torch1.9.0/index.html\n",
            "Collecting mmcv-full\n",
            "  Downloading https://download.openmmlab.com/mmcv/dist/cu111/torch1.9.0/mmcv_full-1.7.0-cp38-cp38-manylinux1_x86_64.whl (49.7 MB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 49.7 MB 327 kB/s \n",
            "\u001b[?25hCollecting addict\n",
            "  Downloading addict-2.4.0-py3-none-any.whl (3.8 kB)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.8/dist-packages (from mmcv-full) (21.3)\n",
            "Requirement already satisfied: opencv-python>=3 in /usr/local/lib/python3.8/dist-packages (from mmcv-full) (4.6.0.66)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.8/dist-packages (from mmcv-full) (6.0)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.8/dist-packages (from mmcv-full) (7.1.2)\n",
            "Collecting yapf\n",
            "  Downloading yapf-0.32.0-py2.py3-none-any.whl (190 kB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 190 kB 27.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from mmcv-full) (1.21.6)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging->mmcv-full) (3.0.9)\n",
            "Installing collected packages: yapf, addict, mmcv-full\n",
            "Successfully installed addict-2.4.0 mmcv-full-1.7.0 yapf-0.32.0\n",
            "Cloning into 'Kfashion'...\n",
            "remote: Enumerating objects: 203, done.\u001b[K\n",
            "remote: Counting objects: 100% (203/203), done.\u001b[K\n",
            "remote: Compressing objects: 100% (141/141), done.\u001b[K\n",
            "remote: Total 203 (delta 74), reused 142 (delta 53), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (203/203), 2.48 MiB | 27.94 MiB/s, done.\n",
            "Resolving deltas: 100% (74/74), done.\n",
            "/content/Kfashion/mmdetection/Kfashion\n",
            "Cloning into 'mmdetection'...\n",
            "remote: Enumerating objects: 32889, done.\u001b[K\n",
            "remote: Counting objects: 100% (204/204), done.\u001b[K\n",
            "remote: Compressing objects: 100% (190/190), done.\u001b[K\n",
            "remote: Total 32889 (delta 53), reused 93 (delta 13), pack-reused 32685\u001b[K\n",
            "Receiving objects: 100% (32889/32889), 44.98 MiB | 17.55 MiB/s, done.\n",
            "Resolving deltas: 100% (23166/23166), done.\n",
            "/content/Kfashion/mmdetection/Kfashion/mmdetection\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Obtaining file:///content/Kfashion/mmdetection/Kfashion/mmdetection\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.8/dist-packages (from mmdet==2.26.0) (3.2.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from mmdet==2.26.0) (1.21.6)\n",
            "Requirement already satisfied: pycocotools in /usr/local/lib/python3.8/dist-packages (from mmdet==2.26.0) (2.0.6)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.8/dist-packages (from mmdet==2.26.0) (1.7.3)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.8/dist-packages (from mmdet==2.26.0) (1.15.0)\n",
            "Requirement already satisfied: terminaltables in /usr/local/lib/python3.8/dist-packages (from mmdet==2.26.0) (3.1.10)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib->mmdet==2.26.0) (3.0.9)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib->mmdet==2.26.0) (2.8.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.8/dist-packages (from matplotlib->mmdet==2.26.0) (0.11.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib->mmdet==2.26.0) (1.4.4)\n",
            "Installing collected packages: mmdet\n",
            "  Attempting uninstall: mmdet\n",
            "    Found existing installation: mmdet 2.26.0\n",
            "    Can't uninstall 'mmdet'. No files were found to uninstall.\n",
            "  Running setup.py develop for mmdet\n",
            "Successfully installed mmdet-2.26.0\n"
          ]
        }
      ],
      "source": [
        "# install dependencies: (use cu111 because colab has CUDA 11.1)\n",
        "!pip install torch==1.9.0+cu111 torchvision==0.10.0+cu111 -f https://download.pytorch.org/whl/torch_stable.html\n",
        "\n",
        "# install mmcv-full thus we could use CUDA operators\n",
        "!pip install mmcv-full -f https://download.openmmlab.com/mmcv/dist/cu111/torch1.9.0/index.html\n",
        "\n",
        "# Install kfashion\n",
        "!rm -rf Kfashion\n",
        "!git clone https://github.com/sanso62/Kfashion.git\n",
        "%cd Kfashion\n",
        "\n",
        "# Install mmdetection\n",
        "!rm -rf mmdetection\n",
        "!git clone https://github.com/open-mmlab/mmdetection.git\n",
        "%cd mmdetection\n",
        "\n",
        "!pip install -e ."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2u1frXVZ-aZK",
        "outputId": "12580a91-5825-45c0-ac0c-feaba1606f89"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/mmcv/__init__.py:20: UserWarning: On January 1, 2023, MMCV will release v2.0.0, in which it will remove components related to the training process and add a data transformation module. In addition, it will rename the package names mmcv to mmcv-lite and mmcv-full to mmcv. See https://github.com/open-mmlab/mmcv/blob/master/docs/en/compatibility.md for more details.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "{'sys.platform': 'linux',\n",
              " 'Python': '3.8.16 (default, Dec  7 2022, 01:12:13) [GCC 7.5.0]',\n",
              " 'CUDA available': True,\n",
              " 'GPU 0': 'Tesla T4',\n",
              " 'CUDA_HOME': '/usr/local/cuda',\n",
              " 'NVCC': 'Cuda compilation tools, release 11.2, V11.2.152',\n",
              " 'GCC': 'x86_64-linux-gnu-gcc (Ubuntu 7.5.0-3ubuntu1~18.04) 7.5.0',\n",
              " 'PyTorch': '1.9.0+cu111',\n",
              " 'PyTorch compiling details': 'PyTorch built with:\\n  - GCC 7.3\\n  - C++ Version: 201402\\n  - Intel(R) Math Kernel Library Version 2020.0.0 Product Build 20191122 for Intel(R) 64 architecture applications\\n  - Intel(R) MKL-DNN v2.1.2 (Git Hash 98be7e8afa711dc9b66c8ff3504129cb82013cdb)\\n  - OpenMP 201511 (a.k.a. OpenMP 4.5)\\n  - NNPACK is enabled\\n  - CPU capability usage: AVX2\\n  - CUDA Runtime 11.1\\n  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86\\n  - CuDNN 8.0.5\\n  - Magma 2.5.2\\n  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.1, CUDNN_VERSION=8.0.5, CXX_COMPILER=/opt/rh/devtoolset-7/root/usr/bin/c++, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.9.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, \\n',\n",
              " 'TorchVision': '0.10.0+cu111',\n",
              " 'OpenCV': '4.6.0',\n",
              " 'MMCV': '1.7.0',\n",
              " 'MMCV Compiler': 'GCC 7.3',\n",
              " 'MMCV CUDA Compiler': '11.1'}"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from mmcv import collect_env\n",
        "collect_env()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RGk-thF5-iGn",
        "outputId": "f90e2729-4c99-4ee9-a31f-baaf3b0a1043"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1.9.0+cu111 True\n",
            "2.26.0\n",
            "11.1\n",
            "GCC 7.3\n"
          ]
        }
      ],
      "source": [
        "# Check Pytorch installation\n",
        "import torch, torchvision\n",
        "print(torch.__version__, torch.cuda.is_available())\n",
        "\n",
        "# Check MMDetection installation\n",
        "import mmdet\n",
        "print(mmdet.__version__)\n",
        "\n",
        "# Check mmcv installation\n",
        "from mmcv.ops import get_compiling_cuda_version, get_compiler_version\n",
        "print(get_compiling_cuda_version())\n",
        "print(get_compiler_version())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "573_0oqeIOSl"
      },
      "source": [
        "## Fine Tunning: Kfashion Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bnBGgCpR3xV6"
      },
      "source": [
        "Data Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DXbg8FTSrUBV",
        "outputId": "e8835959-e136-40e0-c7bd-255bf4fdab4a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "# load dataset\n",
        "# !wget https://github.com/matterport/Mask_RCNN/releases/download/v2.1/balloon_dataset.zip\n",
        "# !unzip -q balloon_dataset.zip\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "l7-pof6-4rIE"
      },
      "outputs": [],
      "source": [
        "import mmcv\n",
        "from mmcv.runner import load_checkpoint\n",
        "\n",
        "from mmdet.apis import inference_detector, show_result_pyplot, set_random_seed\n",
        "from mmdet.models import build_detector\n",
        "from mmdet.datasets import build_dataset\n",
        "from mmdet.models import build_detector\n",
        "from mmdet.apis import train_detector\n",
        "import datetime"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "29WLHCO6VIS9"
      },
      "outputs": [],
      "source": [
        "import copy\n",
        "import os.path as osp\n",
        "\n",
        "import mmcv\n",
        "import numpy as np\n",
        "\n",
        "from mmdet.datasets.builder import DATASETS\n",
        "from mmdet.datasets.custom import CustomDataset\n",
        "\n",
        "import json\n",
        "import zipfile\n",
        "import os\n",
        "import shutil\n",
        "import re\n",
        "import random\n",
        "import sys"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "qo4dezJrjWOg"
      },
      "outputs": [],
      "source": [
        "try:\n",
        "    shutil.rmtree(\"/content/Kfashion/mmdetection/datasetzip\")\n",
        "except:\n",
        "    pass"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "LLuVVZQZFqRH"
      },
      "outputs": [],
      "source": [
        "!rm -rf datasetzip\n",
        "!mkdir datasetzip\n",
        "!unzip -q /content/drive/MyDrive/Kfashion_dataset.zip -d /content/Kfashion/mmdetection/datasetzip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "0McOdJod1n80"
      },
      "outputs": [],
      "source": [
        "# coco datasetìœ¼ë¡œ í”„ë¦¬ íŠ¸ë ˆì´ë‹ëœ mask_rcnn config ê°€ì ¸ì˜¤ê¸°\n",
        "from mmcv import Config\n",
        "cfg = Config.fromfile('./configs/mask_rcnn/mask_rcnn_r50_caffe_fpn_mstrain-poly_1x_coco.py')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "385TwneFTkvx",
        "outputId": "2d3da089-59bb-4df5-eb5f-d1ea3e33c9a6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--2022-12-16 14:14:46--  https://download.openmmlab.com/mmdetection/v2.0/mask_rcnn/mask_rcnn_r50_caffe_fpn_mstrain-poly_3x_coco/mask_rcnn_r50_caffe_fpn_mstrain-poly_3x_coco_bbox_mAP-0.408__segm_mAP-0.37_20200504_163245-42aa3d00.pth\n",
            "Resolving download.openmmlab.com (download.openmmlab.com)... 163.181.82.219, 163.181.82.218, 163.181.82.215, ...\n",
            "Connecting to download.openmmlab.com (download.openmmlab.com)|163.181.82.219|:443... connected.\n",
            "HTTP request sent, awaiting response... 206 Partial Content\n",
            "Length: 177867103 (170M), 177867102 (170M) remaining [application/octet-stream]\n",
            "Saving to: â€˜../log/latest.pthâ€™\n",
            "\n",
            "../log/latest.pth   100%[===================>] 169.63M  12.8MB/s    in 16s     \n",
            "\n",
            "2022-12-16 14:15:06 (10.5 MB/s) - â€˜../log/latest.pthâ€™ saved [177867103/177867103]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget -c https://download.openmmlab.com/mmdetection/v2.0/mask_rcnn/mask_rcnn_r50_caffe_fpn_mstrain-poly_3x_coco/mask_rcnn_r50_caffe_fpn_mstrain-poly_3x_coco_bbox_mAP-0.408__segm_mAP-0.37_20200504_163245-42aa3d00.pth \\\n",
        "      -O ../log/latest.pth"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "Mn33CM91L_hg"
      },
      "outputs": [],
      "source": [
        "categories = [{\"id\": 0, \"name\": \"coat\"},\n",
        "              {\"id\": 1, \"name\": \"jacket\"},\n",
        "              {\"id\": 2, \"name\": \"jumper\"},\n",
        "              {\"id\": 3, \"name\": \"cardigan\"},\n",
        "              {\"id\": 4, \"name\": \"blouse\"},\n",
        "              {\"id\": 5, \"name\": \"t-shirt\"},\n",
        "              {\"id\": 6, \"name\": \"sweater\"},\n",
        "              {\"id\": 7, \"name\": \"shirt\"},\n",
        "              {\"id\": 8, \"name\": \"onepiece(dress)\"},\n",
        "              {\"id\": 9, \"name\": \"jumpsuite\"},\n",
        "              {\"id\": 10, \"name\": \"pants\"},\n",
        "              {\"id\": 11, \"name\": \"skirt\"}]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "3eOknXjsTkvt",
        "outputId": "6d990fab-e131-4f95-b8f1-042e646479aa"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "**\n",
            "<built-in function dir>\n",
            "**\n",
            "<built-in function dir>\n",
            "**\n",
            "<built-in function dir>\n",
            "**\n",
            "<built-in function dir>\n",
            "**\n",
            "<built-in function dir>\n",
            "**\n",
            "<built-in function dir>\n",
            "**\n",
            "<built-in function dir>\n",
            "**\n",
            "<built-in function dir>\n",
            "**\n",
            "<built-in function dir>\n",
            "**\n",
            "<built-in function dir>\n",
            "**\n",
            "<built-in function dir>\n",
            "**\n",
            "<built-in function dir>\n",
            "**\n",
            "<built-in function dir>\n",
            "**\n",
            "<built-in function dir>\n",
            "**\n",
            "<built-in function dir>\n",
            "data done\n",
            "Config:\n",
            "model = dict(\n",
            "    type='MaskRCNN',\n",
            "    backbone=dict(\n",
            "        type='ResNet',\n",
            "        depth=50,\n",
            "        num_stages=4,\n",
            "        out_indices=(0, 1, 2, 3),\n",
            "        frozen_stages=1,\n",
            "        norm_cfg=dict(type='BN', requires_grad=False),\n",
            "        norm_eval=True,\n",
            "        style='caffe',\n",
            "        init_cfg=dict(\n",
            "            type='Pretrained',\n",
            "            checkpoint='open-mmlab://detectron2/resnet50_caffe')),\n",
            "    neck=dict(\n",
            "        type='FPN',\n",
            "        in_channels=[256, 512, 1024, 2048],\n",
            "        out_channels=256,\n",
            "        num_outs=5),\n",
            "    rpn_head=dict(\n",
            "        type='RPNHead',\n",
            "        in_channels=256,\n",
            "        feat_channels=256,\n",
            "        anchor_generator=dict(\n",
            "            type='AnchorGenerator',\n",
            "            scales=[8],\n",
            "            ratios=[0.5, 1.0, 2.0],\n",
            "            strides=[4, 8, 16, 32, 64]),\n",
            "        bbox_coder=dict(\n",
            "            type='DeltaXYWHBBoxCoder',\n",
            "            target_means=[0.0, 0.0, 0.0, 0.0],\n",
            "            target_stds=[1.0, 1.0, 1.0, 1.0]),\n",
            "        loss_cls=dict(\n",
            "            type='CrossEntropyLoss', use_sigmoid=True, loss_weight=1.0),\n",
            "        loss_bbox=dict(type='L1Loss', loss_weight=1.0)),\n",
            "    roi_head=dict(\n",
            "        type='StandardRoIHead',\n",
            "        bbox_roi_extractor=dict(\n",
            "            type='SingleRoIExtractor',\n",
            "            roi_layer=dict(type='RoIAlign', output_size=7, sampling_ratio=0),\n",
            "            out_channels=256,\n",
            "            featmap_strides=[4, 8, 16, 32]),\n",
            "        bbox_head=dict(\n",
            "            type='Shared2FCBBoxHead',\n",
            "            in_channels=256,\n",
            "            fc_out_channels=1024,\n",
            "            roi_feat_size=7,\n",
            "            num_classes=12,\n",
            "            bbox_coder=dict(\n",
            "                type='DeltaXYWHBBoxCoder',\n",
            "                target_means=[0.0, 0.0, 0.0, 0.0],\n",
            "                target_stds=[0.1, 0.1, 0.2, 0.2]),\n",
            "            reg_class_agnostic=False,\n",
            "            loss_cls=dict(\n",
            "                type='CrossEntropyLoss', use_sigmoid=False, loss_weight=1.0),\n",
            "            loss_bbox=dict(type='L1Loss', loss_weight=1.0)),\n",
            "        mask_roi_extractor=dict(\n",
            "            type='SingleRoIExtractor',\n",
            "            roi_layer=dict(type='RoIAlign', output_size=14, sampling_ratio=0),\n",
            "            out_channels=256,\n",
            "            featmap_strides=[4, 8, 16, 32]),\n",
            "        mask_head=dict(\n",
            "            type='FCNMaskHead',\n",
            "            num_convs=4,\n",
            "            in_channels=256,\n",
            "            conv_out_channels=256,\n",
            "            num_classes=12,\n",
            "            loss_mask=dict(\n",
            "                type='CrossEntropyLoss', use_mask=True, loss_weight=1.0))),\n",
            "    train_cfg=dict(\n",
            "        rpn=dict(\n",
            "            assigner=dict(\n",
            "                type='MaxIoUAssigner',\n",
            "                pos_iou_thr=0.7,\n",
            "                neg_iou_thr=0.3,\n",
            "                min_pos_iou=0.3,\n",
            "                match_low_quality=True,\n",
            "                ignore_iof_thr=-1),\n",
            "            sampler=dict(\n",
            "                type='RandomSampler',\n",
            "                num=256,\n",
            "                pos_fraction=0.5,\n",
            "                neg_pos_ub=-1,\n",
            "                add_gt_as_proposals=False),\n",
            "            allowed_border=-1,\n",
            "            pos_weight=-1,\n",
            "            debug=False),\n",
            "        rpn_proposal=dict(\n",
            "            nms_pre=2000,\n",
            "            max_per_img=1000,\n",
            "            nms=dict(type='nms', iou_threshold=0.7),\n",
            "            min_bbox_size=0),\n",
            "        rcnn=dict(\n",
            "            assigner=dict(\n",
            "                type='MaxIoUAssigner',\n",
            "                pos_iou_thr=0.5,\n",
            "                neg_iou_thr=0.5,\n",
            "                min_pos_iou=0.5,\n",
            "                match_low_quality=True,\n",
            "                ignore_iof_thr=-1),\n",
            "            sampler=dict(\n",
            "                type='RandomSampler',\n",
            "                num=512,\n",
            "                pos_fraction=0.25,\n",
            "                neg_pos_ub=-1,\n",
            "                add_gt_as_proposals=True),\n",
            "            mask_size=28,\n",
            "            pos_weight=-1,\n",
            "            debug=False)),\n",
            "    test_cfg=dict(\n",
            "        rpn=dict(\n",
            "            nms_pre=1000,\n",
            "            max_per_img=1000,\n",
            "            nms=dict(type='nms', iou_threshold=0.7),\n",
            "            min_bbox_size=0),\n",
            "        rcnn=dict(\n",
            "            score_thr=0.05,\n",
            "            nms=dict(type='nms', iou_threshold=0.5),\n",
            "            max_per_img=100,\n",
            "            mask_thr_binary=0.5)))\n",
            "dataset_type = 'COCODataset'\n",
            "data_root = 'data/coco/'\n",
            "img_norm_cfg = dict(\n",
            "    mean=[103.53, 116.28, 123.675], std=[1.0, 1.0, 1.0], to_rgb=False)\n",
            "train_pipeline = [\n",
            "    dict(type='LoadImageFromFile'),\n",
            "    dict(\n",
            "        type='LoadAnnotations',\n",
            "        with_bbox=True,\n",
            "        with_mask=True,\n",
            "        poly2mask=False),\n",
            "    dict(\n",
            "        type='Resize',\n",
            "        img_scale=[(1333, 640), (1333, 672), (1333, 704), (1333, 736),\n",
            "                   (1333, 768), (1333, 800)],\n",
            "        multiscale_mode='value',\n",
            "        keep_ratio=True),\n",
            "    dict(type='RandomFlip', flip_ratio=0.5),\n",
            "    dict(\n",
            "        type='Normalize',\n",
            "        mean=[103.53, 116.28, 123.675],\n",
            "        std=[1.0, 1.0, 1.0],\n",
            "        to_rgb=False),\n",
            "    dict(type='Pad', size_divisor=32),\n",
            "    dict(type='DefaultFormatBundle'),\n",
            "    dict(type='Collect', keys=['img', 'gt_bboxes', 'gt_labels', 'gt_masks'])\n",
            "]\n",
            "test_pipeline = [\n",
            "    dict(type='LoadImageFromFile'),\n",
            "    dict(\n",
            "        type='MultiScaleFlipAug',\n",
            "        img_scale=(1333, 800),\n",
            "        flip=False,\n",
            "        transforms=[\n",
            "            dict(type='Resize', keep_ratio=True),\n",
            "            dict(type='RandomFlip'),\n",
            "            dict(\n",
            "                type='Normalize',\n",
            "                mean=[103.53, 116.28, 123.675],\n",
            "                std=[1.0, 1.0, 1.0],\n",
            "                to_rgb=False),\n",
            "            dict(type='Pad', size_divisor=32),\n",
            "            dict(type='ImageToTensor', keys=['img']),\n",
            "            dict(type='Collect', keys=['img'])\n",
            "        ])\n",
            "]\n",
            "data = dict(\n",
            "    samples_per_gpu=2,\n",
            "    workers_per_gpu=2,\n",
            "    train=dict(\n",
            "        type='CocoDataset',\n",
            "        ann_file=\n",
            "        '/content/Kfashion/mmdetection/kfashion/task_3-1_02top_04shirt_01-2022_08_23_05_52_15-coco 1.0.zip/train/annotation_kfashion.json',\n",
            "        img_prefix=\n",
            "        '/content/Kfashion/mmdetection/kfashion/task_3-1_02top_04shirt_01-2022_08_23_05_52_15-coco 1.0.zip/train/',\n",
            "        pipeline=[\n",
            "            dict(type='LoadImageFromFile'),\n",
            "            dict(\n",
            "                type='LoadAnnotations',\n",
            "                with_bbox=True,\n",
            "                with_mask=True,\n",
            "                poly2mask=False),\n",
            "            dict(\n",
            "                type='Resize',\n",
            "                img_scale=[(1333, 640), (1333, 672), (1333, 704), (1333, 736),\n",
            "                           (1333, 768), (1333, 800)],\n",
            "                multiscale_mode='value',\n",
            "                keep_ratio=True),\n",
            "            dict(type='RandomFlip', flip_ratio=0.5),\n",
            "            dict(\n",
            "                type='Normalize',\n",
            "                mean=[103.53, 116.28, 123.675],\n",
            "                std=[1.0, 1.0, 1.0],\n",
            "                to_rgb=False),\n",
            "            dict(type='Pad', size_divisor=32),\n",
            "            dict(type='DefaultFormatBundle'),\n",
            "            dict(\n",
            "                type='Collect',\n",
            "                keys=['img', 'gt_bboxes', 'gt_labels', 'gt_masks'])\n",
            "        ],\n",
            "        classes=('coat', 'jacket', 'jumper', 'cardigan', 'blouse', 't-shirt',\n",
            "                 'sweater', 'shirt', 'onepiece(dress)', 'jumpsuite', 'pants',\n",
            "                 'skirt')),\n",
            "    val=dict(\n",
            "        type='CocoDataset',\n",
            "        ann_file=\n",
            "        '/content/Kfashion/mmdetection/kfashion/task_3-1_02top_04shirt_01-2022_08_23_05_52_15-coco 1.0.zip/val/annotation_kfashion.json',\n",
            "        img_prefix=\n",
            "        '/content/Kfashion/mmdetection/kfashion/task_3-1_02top_04shirt_01-2022_08_23_05_52_15-coco 1.0.zip/val/',\n",
            "        pipeline=[\n",
            "            dict(type='LoadImageFromFile'),\n",
            "            dict(\n",
            "                type='MultiScaleFlipAug',\n",
            "                img_scale=(1333, 800),\n",
            "                flip=False,\n",
            "                transforms=[\n",
            "                    dict(type='Resize', keep_ratio=True),\n",
            "                    dict(type='RandomFlip'),\n",
            "                    dict(\n",
            "                        type='Normalize',\n",
            "                        mean=[103.53, 116.28, 123.675],\n",
            "                        std=[1.0, 1.0, 1.0],\n",
            "                        to_rgb=False),\n",
            "                    dict(type='Pad', size_divisor=32),\n",
            "                    dict(type='ImageToTensor', keys=['img']),\n",
            "                    dict(type='Collect', keys=['img'])\n",
            "                ])\n",
            "        ],\n",
            "        classes=('coat', 'jacket', 'jumper', 'cardigan', 'blouse', 't-shirt',\n",
            "                 'sweater', 'shirt', 'onepiece(dress)', 'jumpsuite', 'pants',\n",
            "                 'skirt')),\n",
            "    test=dict(\n",
            "        type='CocoDataset',\n",
            "        ann_file=\n",
            "        '/content/Kfashion/mmdetection/kfashion/task_3-1_02top_04shirt_01-2022_08_23_05_52_15-coco 1.0.zip/val/annotation_kfashion.json',\n",
            "        img_prefix=\n",
            "        '/content/Kfashion/mmdetection/kfashion/task_3-1_02top_04shirt_01-2022_08_23_05_52_15-coco 1.0.zip/val/',\n",
            "        pipeline=[\n",
            "            dict(type='LoadImageFromFile'),\n",
            "            dict(\n",
            "                type='MultiScaleFlipAug',\n",
            "                img_scale=(1333, 800),\n",
            "                flip=False,\n",
            "                transforms=[\n",
            "                    dict(type='Resize', keep_ratio=True),\n",
            "                    dict(type='RandomFlip'),\n",
            "                    dict(\n",
            "                        type='Normalize',\n",
            "                        mean=[103.53, 116.28, 123.675],\n",
            "                        std=[1.0, 1.0, 1.0],\n",
            "                        to_rgb=False),\n",
            "                    dict(type='Pad', size_divisor=32),\n",
            "                    dict(type='ImageToTensor', keys=['img']),\n",
            "                    dict(type='Collect', keys=['img'])\n",
            "                ])\n",
            "        ],\n",
            "        classes=('coat', 'jacket', 'jumper', 'cardigan', 'blouse', 't-shirt',\n",
            "                 'sweater', 'shirt', 'onepiece(dress)', 'jumpsuite', 'pants',\n",
            "                 'skirt')))\n",
            "evaluation = dict(metric=['bbox', 'segm'], interval=12)\n",
            "optimizer = dict(type='SGD', lr=0.0025, momentum=0.9, weight_decay=0.0001)\n",
            "optimizer_config = dict(grad_clip=None)\n",
            "lr_config = dict(\n",
            "    policy='step',\n",
            "    warmup=None,\n",
            "    warmup_iters=500,\n",
            "    warmup_ratio=0.001,\n",
            "    step=[8, 11])\n",
            "runner = dict(type='EpochBasedRunner', max_epochs=12)\n",
            "checkpoint_config = dict(interval=12)\n",
            "log_config = dict(\n",
            "    interval=10,\n",
            "    hooks=[dict(type='TextLoggerHook'),\n",
            "           dict(type='TensorboardLoggerHook')])\n",
            "custom_hooks = [dict(type='NumClassCheckHook')]\n",
            "dist_params = dict(backend='nccl')\n",
            "log_level = 'INFO'\n",
            "load_from = '../log/latest.pth'\n",
            "resume_from = None\n",
            "workflow = [('train', 1)]\n",
            "opencv_num_threads = 0\n",
            "mp_start_method = 'fork'\n",
            "auto_scale_lr = dict(enable=False, base_batch_size=16)\n",
            "work_dir = '../log/'\n",
            "seed = 0\n",
            "device = 'cuda'\n",
            "gpu_ids = range(0, 1)\n",
            "\n",
            "Config done\n",
            "loading annotations into memory...\n",
            "Done (t=0.01s)\n",
            "creating index...\n",
            "index created!\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2022-12-16 14:15:50,241 - mmdet - INFO - Automatic scaling of learning rate (LR) has been disabled.\n",
            "2022-12-16 14:15:50,252 - mmdet - INFO - load checkpoint from local path: ../log/latest.pth\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loading annotations into memory...\n",
            "Done (t=0.00s)\n",
            "creating index...\n",
            "index created!\n"
          ]
        },
        {
          "ename": "UnpicklingError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mUnpicklingError\u001b[0m                           Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-16-73f906b1506a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    130\u001b[0m     \u001b[0mmmcv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmkdir_or_exist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mosp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabspath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcfg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwork_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    131\u001b[0m     \u001b[0;31m# add timestamp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 132\u001b[0;31m     \u001b[0mtrain_detector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdatasets\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcfg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdistributed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimestamp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdatetime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatetime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrftime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"%Y%m%d-%H%M%S\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/content/Kfashion/mmdetection/Kfashion/mmdetection/mmdet/apis/train.py\u001b[0m in \u001b[0;36mtrain_detector\u001b[0;34m(model, dataset, cfg, distributed, validate, timestamp, meta)\u001b[0m\n\u001b[1;32m    243\u001b[0m         \u001b[0mrunner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresume\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcfg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresume_from\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    244\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mcfg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_from\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 245\u001b[0;31m         \u001b[0mrunner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_checkpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcfg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_from\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    246\u001b[0m     \u001b[0mrunner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_loaders\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcfg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mworkflow\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/mmcv/runner/base_runner.py\u001b[0m in \u001b[0;36mload_checkpoint\u001b[0;34m(self, filename, map_location, strict, revise_keys)\u001b[0m\n\u001b[1;32m    347\u001b[0m         \u001b[0mrevise_keys\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mList\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mr'^module.'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    348\u001b[0m     ) -> Union[Dict, OrderedDict]:\n\u001b[0;32m--> 349\u001b[0;31m         return load_checkpoint(\n\u001b[0m\u001b[1;32m    350\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    351\u001b[0m             \u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/mmcv/runner/checkpoint.py\u001b[0m in \u001b[0;36mload_checkpoint\u001b[0;34m(model, filename, map_location, strict, logger, revise_keys)\u001b[0m\n\u001b[1;32m    636\u001b[0m         \u001b[0mdict\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mOrderedDict\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mThe\u001b[0m \u001b[0mloaded\u001b[0m \u001b[0mcheckpoint\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    637\u001b[0m     \"\"\"\n\u001b[0;32m--> 638\u001b[0;31m     \u001b[0mcheckpoint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_load_checkpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_location\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogger\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    639\u001b[0m     \u001b[0;31m# OrderedDict is a subclass of dict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    640\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcheckpoint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/mmcv/runner/checkpoint.py\u001b[0m in \u001b[0;36m_load_checkpoint\u001b[0;34m(filename, map_location, logger)\u001b[0m\n\u001b[1;32m    570\u001b[0m            \u001b[0minformation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwhich\u001b[0m \u001b[0mdepends\u001b[0m \u001b[0mon\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mcheckpoint\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    571\u001b[0m     \"\"\"\n\u001b[0;32m--> 572\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mCheckpointLoader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_checkpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_location\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogger\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    573\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    574\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/mmcv/runner/checkpoint.py\u001b[0m in \u001b[0;36mload_checkpoint\u001b[0;34m(cls, filename, map_location, logger)\u001b[0m\n\u001b[1;32m    312\u001b[0m         mmcv.print_log(\n\u001b[1;32m    313\u001b[0m             f'load checkpoint from {class_name[10:]} path: {filename}', logger)\n\u001b[0;32m--> 314\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mcheckpoint_loader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_location\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    315\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    316\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/mmcv/runner/checkpoint.py\u001b[0m in \u001b[0;36mload_from_local\u001b[0;34m(filename, map_location)\u001b[0m\n\u001b[1;32m    332\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mosp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misfile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    333\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mFileNotFoundError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'{filename} can not be found.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 334\u001b[0;31m     \u001b[0mcheckpoint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_location\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmap_location\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    335\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mcheckpoint\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    336\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, **pickle_load_args)\u001b[0m\n\u001b[1;32m    606\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopened_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    607\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0m_load\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopened_zipfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_location\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpickle_load_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 608\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_legacy_load\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopened_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_location\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpickle_load_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    609\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    610\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36m_legacy_load\u001b[0;34m(f, map_location, pickle_module, **pickle_load_args)\u001b[0m\n\u001b[1;32m    775\u001b[0m             \"functionality.\")\n\u001b[1;32m    776\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 777\u001b[0;31m     \u001b[0mmagic_number\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpickle_load_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    778\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mmagic_number\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mMAGIC_NUMBER\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    779\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Invalid magic number; corrupt file?\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mUnpicklingError\u001b[0m: invalid load key, '\\x0a'."
          ]
        }
      ],
      "source": [
        "for (_, _, files) in os.walk(\"/content/Kfashion/mmdetection/datasetzip\"):\n",
        "    for i,f in enumerate(files):\n",
        "        try:\n",
        "            print(\"**\")\n",
        "            shutil.rmtree(\"/content/Kfashion/mmdetection/kfashion\")\n",
        "        except:\n",
        "            pass\n",
        "        os.mkdir(\"/content/Kfashion/mmdetection/kfashion/\")\n",
        "        zipfile.ZipFile(\"/content/Kfashion/mmdetection/datasetzip/\"+f).extractall(\"/content/Kfashion/mmdetection/kfashion/\"+f)\n",
        "        # shutil.unpack_archive(\"/content/Kfashion/mmdetection/datasetzip/\"+f, \"/content/Kfashion/mmdetection/kfashion/\"+f, \"zip\")\n",
        "        os.mkdir(\"/content/Kfashion/mmdetection/kfashion/\"+f+\"/train\")\n",
        "        os.mkdir(\"/content/Kfashion/mmdetection/kfashion/\"+f+\"/val\")\n",
        "        print(dir)\n",
        "        train_img_id_list={}\n",
        "        val_img_id_list={}\n",
        "        train_images=[]\n",
        "        val_images=[]\n",
        "        train_annotations=[]\n",
        "        val_annotations=[]\n",
        "        with open(\"/content/Kfashion/mmdetection/kfashion/\"+f+\"/annotations/instances_default.json\", \"r\") as file:\n",
        "            label=json.load(file)\n",
        "            random.shuffle(label[\"images\"])\n",
        "            len_images=len(label[\"images\"])\n",
        "            for img in label[\"images\"][:int(len_images*0.9)]:\n",
        "                file_name=re.sub(\"/.*/\",\"\",img[\"file_name\"])\n",
        "                train_img_id_list[file_name]=img[\"id\"]\n",
        "                img[\"file_name\"]=file_name\n",
        "                train_images.append(img)   \n",
        "\n",
        "            for img in label[\"images\"][int(len_images*0.9):]:\n",
        "                file_name=re.sub(\"/.*/\",\"\",img[\"file_name\"])\n",
        "                val_img_id_list[file_name]=img[\"id\"]\n",
        "                img[\"file_name\"]=file_name\n",
        "                val_images.append(img)  \n",
        "\n",
        "            category=label[\"categories\"][0][\"name\"]\n",
        "            for c in categories:\n",
        "              if c[\"name\"]==category:\n",
        "                category_id=c[\"id\"]\n",
        "                break\n",
        "\n",
        "            for ann in label[\"annotations\"]:\n",
        "                ann[\"category_id\"]=category_id\n",
        "                if ann[\"image_id\"] in train_img_id_list.values():\n",
        "                    train_annotations.append(ann)\n",
        "                elif ann[\"image_id\"] in val_img_id_list.values():\n",
        "                    val_annotations.append(ann)\n",
        "\n",
        "                \n",
        "\n",
        "\n",
        "        jsondata=dict([(\"categories\", categories), (\"images\", train_images), (\"annotations\", train_annotations) ])\n",
        "        with open(\"/content/Kfashion/mmdetection/kfashion/\"+f+\"/train/annotation_kfashion.json\", \"w\") as tf:\n",
        "            json.dump(jsondata, tf)\n",
        "        \n",
        "        jsondata=dict([(\"categories\", categories), (\"images\", val_images), (\"annotations\", val_annotations) ])\n",
        "        with open(f\"/content/Kfashion/mmdetection/kfashion/{f}/val/annotation_kfashion.json\", \"w\") as vf:\n",
        "            json.dump(jsondata, vf)\n",
        "\n",
        "        for img_name in train_img_id_list.keys():        \n",
        "            shutil.move(\"/content/Kfashion/mmdetection/kfashion/\"+f+\"/images/\"+img_name, \"/content/Kfashion/mmdetection/kfashion/\"+f+\"/train/\"+img_name)\n",
        "        for img_name in val_img_id_list.keys():        \n",
        "            shutil.move(\"/content/Kfashion/mmdetection/kfashion/\"+f+\"/images/\"+img_name, \"/content/Kfashion/mmdetection/kfashion/\"+f+\"/val/\"+img_name)\n",
        "    \n",
        "    print(\"data done\")\n",
        "    # Modify dataset type and path\n",
        "\n",
        "    cfg.dataset_type = 'COCODataset'\n",
        "\n",
        "\n",
        "    cfg.data.test.ann_file = \"/content/Kfashion/mmdetection/kfashion/\"+f+\"/val/annotation_kfashion.json\"\n",
        "    cfg.data.test.img_prefix = \"/content/Kfashion/mmdetection/kfashion/\"+f+\"/val/\"\n",
        "    cfg.data.test.classes = (\"coat\", \"jacket\", \"jumper\", \"cardigan\", \"blouse\", \"t-shirt\",\"sweater\", \"shirt\", \"onepiece(dress)\", \"jumpsuite\", \"pants\", \"skirt\")\n",
        "\n",
        "\n",
        "    cfg.data.train.ann_file = \"/content/Kfashion/mmdetection/kfashion/\"+f+\"/train/annotation_kfashion.json\"\n",
        "    cfg.data.train.img_prefix = \"/content/Kfashion/mmdetection/kfashion/\"+f+\"/train/\"\n",
        "    cfg.data.train.classes = (\"coat\", \"jacket\", \"jumper\", \"cardigan\", \"blouse\", \"t-shirt\",\"sweater\", \"shirt\", \"onepiece(dress)\", \"jumpsuite\", \"pants\", \"skirt\")\n",
        "\n",
        "\n",
        "    cfg.data.val.ann_file = \"/content/Kfashion/mmdetection/kfashion/\"+f+\"/val/annotation_kfashion.json\"\n",
        "    cfg.data.val.img_prefix = \"/content/Kfashion/mmdetection/kfashion/\"+f+\"/val/\"\n",
        "    cfg.data.val.classes = (\"coat\", \"jacket\", \"jumper\", \"cardigan\", \"blouse\", \"t-shirt\",\"sweater\", \"shirt\", \"onepiece(dress)\", \"jumpsuite\", \"pants\", \"skirt\")\n",
        "\n",
        "\n",
        "    # # modify num classes of the model in box head\n",
        "    # cfg.model.roi_head.bbox_head.num_classes = 80\n",
        "    # # modify num classes of the model in box head and mask head\n",
        "    cfg.model.roi_head.bbox_head.num_classes = 12\n",
        "    cfg.model.roi_head.mask_head.num_classes = 12\n",
        "    # If we need to finetune a model based on a pre-trained detector, we need to\n",
        "    # use load_from to set the path of log.\n",
        "    cfg.load_from = '../log/latest.pth'\n",
        "\n",
        "    # Set up working dir to save files and logs.\n",
        "    cfg.work_dir = '../log/'\n",
        "\n",
        "    # The original learning rate (LR) is set for 8-GPU training.\n",
        "    # We divide it by 8 since we only use one GPU.\n",
        "    cfg.optimizer.lr = 0.02 / 8\n",
        "    cfg.lr_config.warmup = None\n",
        "    cfg.log_config.interval = 10\n",
        "\n",
        "    # Change the evaluation metric since we use customized dataset.\n",
        "    # cfg.evaluation.metric = 'mAP'/\n",
        "    # We can set the evaluation interval to reduce the evaluation times\n",
        "    cfg.evaluation.interval = 12\n",
        "    # We can set the checkpoint saving interval to reduce the storage cost\n",
        "    cfg.checkpoint_config.interval = 12\n",
        "\n",
        "    cfg.seed = 0\n",
        "    set_random_seed(0, deterministic=False)\n",
        "    cfg.device = 'cuda'\n",
        "    cfg.gpu_ids = range(1)\n",
        "\n",
        "    cfg.log_config.hooks = [\n",
        "        dict(type='TextLoggerHook'),\n",
        "        dict(type='TensorboardLoggerHook')]\n",
        "    print(f'Config:\\n{cfg.pretty_text}')\n",
        "\n",
        "    print(\"Config done\")\n",
        "\n",
        "\n",
        "    datasets = [build_dataset(cfg.data.train)]\n",
        "    model = build_detector(cfg.model)\n",
        "    model.CLASSES = datasets[0].CLASSES\n",
        "    mmcv.mkdir_or_exist(osp.abspath(cfg.work_dir))\n",
        "    # add timestamp\n",
        "    train_detector(model, datasets, cfg, distributed=False, validate=True, timestamp=datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FCxmD0OGTkvz"
      },
      "source": [
        "## ë¡œê·¸ ì‹œê°í™”"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "32Lm-EfSTkvz"
      },
      "outputs": [],
      "source": [
        "\n",
        "%load_ext tensorboard\n",
        "%tensorboard --logdir ./tutorial_exps"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WomGhWs36AYF"
      },
      "source": [
        "# Detection ê²°ê³¼"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Bt94A9v4GvzY"
      },
      "outputs": [],
      "source": [
        "img = mmcv.imread('./balloon/sample.jpg') # í…ŒìŠ¤íŠ¸í•  ìƒ˜í”Œì´ë¯¸ì§€ì˜ ê²½ë¡œëª… ìž…ë ¥\n",
        "\n",
        "model.cfg = cfg\n",
        "result = inference_detector(model, img)\n",
        "show_result_pyplot(model, img, result)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.9 (tags/v3.10.9:1dd9be6, Dec  6 2022, 20:01:21) [MSC v.1934 64 bit (AMD64)]"
    },
    "vscode": {
      "interpreter": {
        "hash": "d4f0abf4b4e06a550281b258cd6c810d114c729ed8b8996b13462e88057d1b62"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
